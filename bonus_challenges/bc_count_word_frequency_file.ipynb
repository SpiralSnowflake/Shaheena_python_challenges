{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a41a6354",
   "metadata": {},
   "source": [
    "Challenge: Count Word Frequency in a Text File\n",
    "Problem\n",
    "1. Write a function that reads a .txt file and counts how many times each word appears. Return a dictionary where the keys are words and the values are the number of times they appear.\n",
    "\n",
    "Example\n",
    "Given a file with:\n",
    "\n",
    "\"The cat and the hat.\"\n",
    "\n",
    "Your output might be:\n",
    "\n",
    "{'the': 2, 'cat': 1, 'and': 1, 'hat': 1}\n",
    "Your Task\n",
    "1. Open and read a .txt file (you can create a small practice file if needed)\n",
    "2. Normalize the text (e.g., lowercase, remove punctuation)\n",
    "3. Split the text into words\n",
    "4. Use a dictionary to count word frequencies\n",
    "5. Return or print the dictionary\n",
    "Concepts Tested\n",
    "File reading\n",
    "String cleanup\n",
    "Dictionaries and loops\n",
    "Stretch Ideas\n",
    "2. Sort the output by most frequent words\n",
    "3. Ignore very common stop words like “the,” “and,” etc.\n",
    "4. Save the results to a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0daf507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing word frequencies in 'test_text.txt':\n",
      "\n",
      "Word Frequencies :\n",
      "  'the': 2\n",
      "  'cat': 1\n",
      "  'and': 1\n",
      "  'hat': 1\n"
     ]
    }
   ],
   "source": [
    "#1. Write a function that reads a .txt file and counts how many times each word appears. \n",
    "# Return a dictionary where the keys are words and the values are the number of times they appear.\n",
    "import os\n",
    "import re\n",
    "def count_word_frequency(filepath):\n",
    "# 1. Open and read a .txt file (you can create a small practice file if needed)\n",
    "    dictionary_word_count = {}\n",
    "    normalized_text=\"\"\n",
    "    with open(filepath, 'r',  encoding='utf-8') as file:\n",
    "        #print(f\"filepath {filepath}\")\n",
    "        text = file.read()\n",
    "        #print(f\"in {filepath} text file {text}\")\n",
    "# 2. Normalize the text (e.g., lowercase, remove punctuation)\n",
    "        normalized_text = re.sub(r'[^\\w\\s]', '', text).lower().strip()\n",
    "        #print(normalized_text)\n",
    "\n",
    "# 3. Split the text into words\n",
    "        words = normalized_text.split()\n",
    "        #print(words)\n",
    "# 4. Use a dictionary to count word frequencies\n",
    "        for word in words:\n",
    "            if word in dictionary_word_count:\n",
    "                dictionary_word_count[word] += 1\n",
    "            else:\n",
    "                dictionary_word_count[word] = 1 \n",
    "                  \n",
    "# 5. Return or print the dictionary\n",
    "    #print(dictionary_word_count)\n",
    "    return dictionary_word_count\n",
    "#print(count_word_frequency('test_text.txt'))\n",
    "sample_text = \"\"\"\n",
    "The cat and the hat.\n",
    "\"\"\"\n",
    "with open(\"test_text.txt\", \"w\") as f:\n",
    "         f.write(sample_text)\n",
    "         #print(\"Created 'test_text.txt' for demonstration.\")\n",
    "\n",
    "file_to_analyze = \"test_text.txt\"\n",
    "print(f\"\\nAnalyzing word frequencies in '{file_to_analyze}':\")\n",
    "frequencies = count_word_frequency(file_to_analyze)\n",
    "\n",
    "if frequencies: #check if the frequencies dictionary is not empty.\n",
    "    print(\"\\nWord Frequencies :\")\n",
    "    for word, count in frequencies.items():\n",
    "        print(f\"  '{word}': {count}\")\n",
    "else:\n",
    "    print(\"No word frequencies to display (file might be empty or not found).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f28a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing word frequencies in 'test_text.txt':\n",
      "\n",
      "Word Frequencies (sorted by word frequencies):\n",
      "  'and': 2\n",
      "  'cat': 2\n",
      "  'hat': 2\n",
      "  'the': 4\n"
     ]
    }
   ],
   "source": [
    "# Sort the output by most frequent words\n",
    "import os\n",
    "import re\n",
    "def count_word_frequency(filepath):\n",
    "# 1. Open and read a .txt file (you can create a small practice file if needed)\n",
    "    dictionary_word_count = {}\n",
    "    normalized_text=\"\"\n",
    "    with open(filepath, 'r') as file:\n",
    "        #print(f\"filepath {filepath}\")\n",
    "        text = file.read()\n",
    "        #print(f\"in {filepath} text file {text}\")\n",
    "# 2. Normalize the text (e.g., lowercase, remove punctuation)\n",
    "        normalized_text = re.sub(r'[^\\w\\s]', '', text).lower().strip()\n",
    "        #print(normalized_text)\n",
    "\n",
    "# 3. Split the text into words\n",
    "        words = normalized_text.split()\n",
    "        #print(words)\n",
    "# 4. Use a dictionary to count word frequencies\n",
    "        for word in words:\n",
    "            if word in dictionary_word_count:\n",
    "                dictionary_word_count[word] += 1\n",
    "            else:\n",
    "                dictionary_word_count[word] = 1 \n",
    "                  \n",
    "# 5. Return or print the dictionary\n",
    "    #print(dictionary_word_count)\n",
    "    return dictionary_word_count\n",
    "#print(count_word_frequency('test_text.txt'))\n",
    "sample_text = \"\"\"\n",
    "The cat and the hat.\n",
    "The cat and the hat.\n",
    "\"\"\"\n",
    "\n",
    "file_to_analyze = \"test_text.txt\"\n",
    "print(f\"\\nAnalyzing word frequencies in '{file_to_analyze}':\")\n",
    "frequencies = count_word_frequency(file_to_analyze)\n",
    "\n",
    "if frequencies: c#heck if the frequencies dictionary is not empty.\n",
    "    print(\"\\nWord Frequencies (sorted by word frequencies):\")\n",
    "    # Sort the items for a more readable output\n",
    "    for word, count in sorted(frequencies.items()):\n",
    "        print(f\"  '{word}': {count}\")\n",
    "else:\n",
    "    print(\"No word frequencies to display (file might be empty or not found).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a69f26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing word frequencies in 'test_text.txt':\n",
      "{'cat': 2, 'hat': 2}\n",
      "\n",
      "Word Frequencies (sorted by word frequencies):\n",
      "  'cat': 2\n",
      "  'hat': 2\n"
     ]
    }
   ],
   "source": [
    "#3. Ignore very common stop words like “the,” “and,” etc.\n",
    "\n",
    "import os\n",
    "import re\n",
    "def count_word_frequency(filepath):\n",
    "# 1. Open and read a .txt file (you can create a small practice file if needed)\n",
    "    dictionary_word_count = {}\n",
    "    normalized_text=\"\"\n",
    "    common_word_list = [\"the\",\"and\"]\n",
    "    with open(filepath, 'r') as file:\n",
    "        #print(f\"filepath {filepath}\")\n",
    "        text = file.read()\n",
    "        #print(f\"in {filepath} text file {text}\")\n",
    "# 2. Normalize the text (e.g., lowercase, remove punctuation)\n",
    "        normalized_text = re.sub(r'[^\\w\\s]', '', text).lower().strip()\n",
    "        #print(normalized_text)\n",
    "\n",
    "# 3. Split the text into words\n",
    "        words = normalized_text.split()\n",
    "        #print(words)\n",
    "# 4. Use a dictionary to count word frequencies\n",
    "        for word in words:\n",
    "           if word in common_word_list:\n",
    "               continue\n",
    "           if word :\n",
    "                    if word in dictionary_word_count:\n",
    "                            dictionary_word_count[word] += 1\n",
    "                    else:\n",
    "                            dictionary_word_count[word] = 1 \n",
    "        #print (dictionary_word_count)\n",
    "                 \n",
    "# 5. Return or print the dictionary\n",
    "    #print(dictionary_word_count)\n",
    "    return dictionary_word_count\n",
    "#print(count_word_frequency('test_text.txt'))\n",
    "sample_text = \"\"\"\n",
    "The cat and the hat.\n",
    "The cat and the hat.\n",
    "\"\"\"\n",
    "\n",
    "file_to_analyze = \"test_text.txt\"\n",
    "print(f\"\\nAnalyzing word frequencies in '{file_to_analyze}':\")\n",
    "frequencies = count_word_frequency(file_to_analyze)\n",
    "\n",
    "if frequencies: #check if the frequencies dictionary is not empty.\n",
    "    print(\"\\nWord Frequencies (sorted by word frequencies):\")\n",
    "    # Sort the items for a more readable output\n",
    "    for word, count in (frequencies.items()):\n",
    "        print(f\"  '{word}': {count}\")\n",
    "else:\n",
    "    print(\"No word frequencies to display (file might be empty or not found).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd097423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Save the results to a new file\n",
    "import os\n",
    "import re\n",
    "def count_word_frequency(filepath):\n",
    "# 1. Open and read a .txt file (you can create a small practice file if needed)\n",
    "    dictionary_word_count = {}\n",
    "    normalized_text=\"\"\n",
    "    with open(filepath, 'r',  encoding='utf-8') as file:\n",
    "        #print(f\"filepath {filepath}\")\n",
    "        text = file.read()\n",
    "        #print(f\"in {filepath} text file {text}\")\n",
    "# 2. Normalize the text (e.g., lowercase, remove punctuation)\n",
    "        normalized_text = re.sub(r'[^\\w\\s]', '', text).lower().strip()\n",
    "        #print(normalized_text)\n",
    "\n",
    "# 3. Split the text into words\n",
    "        words = normalized_text.split()\n",
    "        #print(words)\n",
    "# 4. Use a dictionary to count word frequencies\n",
    "        for word in words:\n",
    "            if word in dictionary_word_count:\n",
    "                dictionary_word_count[word] += 1\n",
    "            else:\n",
    "                dictionary_word_count[word] = 1 \n",
    "                  \n",
    "# 5. Return or print the dictionary\n",
    "    #print(dictionary_word_count)\n",
    "    return dictionary_word_count\n",
    "#print(count_word_frequency('test_text.txt'))\n",
    "sample_text = \"\"\"\n",
    "The cat and the hat.\n",
    "\"\"\"\n",
    "with open(\"test_text.txt\", \"w\") as f:\n",
    "         f.write(sample_text)\n",
    "         #print(\"Created 'test_text.txt' for demonstration.\")\n",
    "\n",
    "file_to_analyze = \"test_text.txt\"\n",
    "#print(f\"\\nAnalyzing word frequencies in '{file_to_analyze}':\")\n",
    "frequencies = count_word_frequency(file_to_analyze)\n",
    "\n",
    "if frequencies: #check if the frequencies dictionary is not empty.\n",
    "    #for word, count in frequencies.items():\n",
    "        #print(f\"  '{word}': {count}\")\n",
    "        with open(\"word_frequencies.txt\", \"w\") as f:\n",
    "            f.write(f\"\\nAnalyzing word frequencies in '{file_to_analyze}':\")\n",
    "            f.write(\"\\nWord Frequencies :\")\n",
    "            for word, count in frequencies.items():\n",
    "                f.write(f\"  '{word}': {count}\")\n",
    "else:\n",
    "    print(\"No word frequencies to display (file might be empty or not found).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
